---
title: "Problem Set 6"
author: "Noah Estrada-Rand"
date: "10/6/2019"
output: pdf_document
---

```{r setup, include=FALSE}
setwd("C:/Users/noahe/Desktop/MGSC310")
knitr::opts_chunk$set(echo = TRUE)
library(MASS)
library(doBy)
library(ggplot2)
library(gmodels)
library(plotROC)
data(Boston)
```

# a) Creating test and training sets
```{r}
Boston$PriceyHome <- ifelse(Boston$medv > 40, 1, 0)

Boston$chas <- factor(Boston$chas)##creates a factor
set.seed(2019)
trainSize <- 0.75
train_idx <- sample(1:nrow(Boston), size = floor(nrow(Boston) * trainSize))
housing_train <- Boston[train_idx,]
housing_test <- Boston[-train_idx,]
```

# b) Mean Value of Variables Across Pricey And Non-Pricey Homes
```{r}
summaryBy( . ~ PriceyHome,data = housing_train)
```
From the above results it becomes apparent that pricey neighborhoods in Boston deviate from non-pricey neighborhoods on mulitple dimensions.  In terms of crime rate, the mean rate of crime in pricey neighborhoods is much lower than that of less pricey neighborhoods.  Moreover, the amount of zoning for residential land over 25,000 square feet is almost double the proportion zoned in non-pricey neighborhoods.  Interstingly, the property tax rate per $10,000 is also lower in pricier neighborhoods.  Lastly, the lower status of the population percent is lower in pricey neighborhoods than less pricey neighborhoods, while the median value of owner occupied homes is much higher in pricier neighborhoods.
# c)
```{r}
ggplot(housing_train,aes(x = tax,y = PriceyHome,color = factor(PriceyHome))) + geom_point() +
  scale_color_manual(values = c("red","navy blue")) +
  labs(title = "Plotted Values of Pricey Homes against Taxes",
       y = "Pricey Home indication",
       x = "Tax Rates per $10,000")

ggplot(housing_train,aes(x =crim,y = PriceyHome,color = factor(PriceyHome))) +geom_point() +
  scale_color_manual(values = c("dark green","red")) + 
  labs(title = "Pricey Home Indication Plotted Against Crime Rates",
       y = "Crime Rates",
       x = "Pricey Home")

ggplot(housing_train,aes(x = zn,y = PriceyHome,color = factor(PriceyHome))) +geom_point()+
  scale_color_manual(values =c("orange","brown")) +
  labs(title = "Pricey Home Indication plotted Against\n Proportion of Land Zoned\nFor Lots over 25,000 sq. ft.",
       x = "Proportion of Land Zoned for Lots over 25,000sqft",
       y = "Pricey Home")
```
From the above plots it becomes apparent that neighborhoods labeled as "pricey" have lower taxes rates, in general, than do non pricey neighborhoods.  Moreover, we are able to observe that all "pricey" neighborhoods are under 20% crime rate while the range of crime rates for non pricey neighborhoods is much broader and reaches higher.  Lastly, when evaluating the proportion of land zoned for residential lots over 25,000 sq.ft. results are not as stark, wit pricey neighborhoods existing at the extremes of land zoned while non pricey neighborhoods have proportions at all levels.

# d) Logit Model of PriceyHome by Charles River Location
```{r}
mod1 <- glm(PriceyHome~chas,data = housing_train,family = binomial)
summary(mod1)
exp(mod1$coefficients)
```
Based on the coefficients above, it appears that a neighborhood located adjacent the Charles River leads to that neighborhood being 453.92% more likely to being placed in the "pricey" category.  In other words, when compared to neighborhoods not adjacent to the Charles river, the probability of having median home values above $40,000 is four and a half times higher than that of non pricey neighborhoods.

# e)
```{r}
mod2 <-glm(PriceyHome ~ chas + crim + lstat + ptratio + zn + rm + tax + rad + nox,
           family = binomial,
           data = housing_train)
summary(mod2)
exp(mod2$coefficients)
```
From the above coefficients, it appears that being located along the Charles River does not have a statistically significant impact on predicting whether or not a neighborhood is in the pricey category. With the addition of other variables from the Boston dataset, it becomes apparent that the location of a neighborhood relative to the Charles River is a confounding variable.  This is due to the fact that its effect changes significantly when considered with other variables, indicating that it changes systematically with other variables, making it an unfavorable predictor.

# f) Generated Class Predictions
```{r}
housing_train$priceyProb <- predict(mod2,type = "response")
housing_test$priceyProb <- predict(mod2,type = "response",newdata = housing_test)

housing_train$PriceyPred <- ifelse(housing_train$priceyProb > .5,1,0)
housing_test$PriceyPred <- ifelse(housing_test$priceyProb >.5,1,0)
head(housing_train$PriceyPred)
head(housing_test$PriceyPred)
```

# g) 
Training Data Confusion Matrix
```{r}
name_of_rows <- c("Not Pricey","Pricey","Sum")
name_of_cols <- c("Predicted Not","Predicted Pricey","Sum")
train_confusion <- table(housing_train$PriceyHome,housing_train$PriceyPred)
train_confusion <- addmargins(train_confusion)
rownames(train_confusion) <- name_of_rows
colnames(train_confusion) <- name_of_cols
print(train_confusion)
```
Test Data Confusion Matrix
```{r}
test_confusion <- table(housing_test$PriceyHome,housing_test$PriceyPred)
test_confusion <- addmargins(test_confusion)
rownames(test_confusion) <- name_of_rows
colnames(test_confusion) <- name_of_cols
print(test_confusion)
```
Training and Test Accuracy Based on Logit Model
```{r}
train_accuracy <- (sum(housing_train$PriceyHome == 1 & housing_train$PriceyPred == 1)+
                    sum(housing_train$PriceyHome == 0 & housing_train$PriceyPred == 0))/length(housing_train$PriceyHome)

test_accuracy <- (sum(housing_test$PriceyHome == 1 & housing_test$PriceyPred == 1)+
                    sum(housing_test$PriceyHome == 0 & housing_test$PriceyPred == 0))/length(housing_test$PriceyHome)
print(train_accuracy)
print(test_accuracy)

```
Training and Test Sensitivity/True Positive Rate
```{r}
train_sensitivity <- sum(housing_train$PriceyHome == 1 & housing_train$PriceyPred == 1)/
  (sum(housing_train$PriceyHome == 1))

test_sensitivity <-sum(housing_test$PriceyHome == 1 & housing_test$PriceyPred == 1)/
  sum(housing_test$PriceyHome == 1)
print(train_sensitivity)
print(test_sensitivity)
```
Training and Test Specificity/True Negative Rate
```{r}
train_specificity <- sum(housing_train$PriceyHome == 0 & housing_train$PriceyPred == 0)/
  sum(housing_train$PriceyHome == 0)

test_specificity <- sum(housing_test$PriceyHome == 0 & housing_test$PriceyPred == 0)/
  sum(housing_test$PriceyHome == 0)
print(train_specificity)
print(test_specificity)
```
Training and Test False Positives
```{r}
train_false_positive <- sum(housing_train$PriceyHome == 0 & housing_train$PriceyPred == 1)

test_false_positive <- sum(housing_test$PriceyHome == 0 & housing_test$PriceyPred == 1)

print(train_false_positive)
print(test_false_positive)
```
Training and Test False Negatives
```{r}
train_false_negative <- sum(housing_train$PriceyHome == 1 & housing_train$PriceyPred == 0)

test_false_negative <- sum(housing_test$PriceyHome == 1 & housing_test$PriceyPred == 0)

print(train_false_negative)
print(test_false_negative)
```

# h) Adjusting the Cutoff
Based on the aforementioned accuracy metrics, I believe we should adjust the cutoff to lower than .5 given the fact that the rate of false positives in both the test and training sets are higher than the false negatives.  However, we also need to consider the ramifications of this shift.  Given the inverse tradeoff that exists between false positives and false negatives, we need to evaluate if having more false negatives than false positives and vice versa presents any significant implications.  In this case, it does not necessarily determine anything life or death related, and only implies a rating of "pricey" or not.  Thus we can adjust as needed to maximize the accuracy and reduce false positives and negatives as much as possible.


# i) ROC Plots
```{r} 
train_ROC <- ggplot(housing_train,aes(m = priceyProb,
                    d = PriceyHome)) +
  geom_roc(labelsize = 3.5,
           cutoffs.at = c(.99,.9,.7,.6,.5,.4,.1,.01)) +
  labs(title = "ROC Curve for Train Data",x = "False Positive Fraction",
       y= "True Positive Fraction")
test_ROC <- ggplot(housing_test,aes(m = priceyProb,
                         d = PriceyHome)) +
  geom_roc(labelsize = 3.5,
           cutoffs.at = c(.99,.9,.7,.6,.5,.4,.1,.01)) +
  labs(title = "ROC Curve for Test Data",x = "False Positive Fraction",
       y= "True Positive Fraction")
train_ROC
test_ROC
```

# j) AUC Calculations 
```{r}
train_AUC <- calc_auc(train_ROC)
test_AUC <- calc_auc(test_ROC)
print(train_AUC)
print(test_AUC)
```
Regarding the model, I would say that the model is slightly overfit due to the fact that the test error is slightly higher than the train data.  This might be indicative of overfitting as the model has become too fit to the train data with the AUC value .01 away from encompassing the entire area under the curve. While the model's performance on the test data is only .02 away, we must observe that the model does not capture as much of the data in the test set as it does in training.  Thus we need to adjust the probability cutoff point perhaps to give the model more flexibility when encountering new data in hopes of having more area under the curve for test data than train data.