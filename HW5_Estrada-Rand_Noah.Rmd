---
title: "Problem Set 5"
author: "Noah Estrada-Rand"
date: "10/1/2019"
output: pdf_document
---

```{r setup, include=FALSE}
setwd("C:/Users/noahe/Desktop/MGSC310")
movies <- read.csv("movie_metadata.csv")
library(tidyverse)
library(margins)
library(forecast)
library(ggplot2)
knitr::opts_chunk$set(echo = TRUE)
```

# 1

# b) Running Given Instructions
```{r}
movies <- movies[!is.na(movies$budget),]
movies <- movies[!is.na(movies$gross),]
movies <- movies[(movies$content_rating != "" & movies$content_rating != "Not Rated"), ]
movies <- movies[movies$budget<4e+8,]
movies$grossM <- movies$gross/1e+6
movies$budgetM <- movies$budget/1e+6
movies$profitM <- movies$grossM-movies$budgetM
movies$rating_simple <- fct_lump(movies$content_rating, n = 4)
set.seed(2019)
train_indx <- sample(1:nrow(movies), 0.8 * nrow(movies), replace=FALSE)
movies_train <- movies[train_indx, ]
movies_test <- movies[-train_indx, ]
```

# c) Summary of the Linear Model Regressing GrossM by IMDB_score and BudgetM
```{r}
mod.gross.score <- lm(grossM ~ imdb_score + budgetM, data = movies_train)
summary(mod.gross.score)
```

# d)
According to the coefficient outputs of the linear model regressing Gross revenue against IMDB scores and Budget, it appears that when holding IMDB scores fixed, increasing the budget has a net positive return for that particular movie.  Thus, increasing spending by one million translates to an increase in gross revenue by $1,009,500.

# e)
```{r}
mod.gross.score.budgetsquared <- lm(grossM~ imdb_score + budgetM + I(budgetM^2), data = movies_train)
summary(mod.gross.score.budgetsquared)
```

# f) Marginal Effects Estimation of Budget Squared Model
```{r}
margins(mod.gross.score.budgetsquared, at = list(budgetM = c(25, 50, 75, 90,
                                                             100, 200,300)))
```
Looking at the results above, it becomes clear that it makes the most sense to increase your budget at lower budget levels to see a larger return.  This effect dissipates, however, the higher your budget becomes.  Thus, if a movie already has a large budget, the returns from an increase in budget will not be as significant, and thus not necessarily worth the investment.

# g)
```{r}
cplot(mod.gross.score.budgetsquared,"budgetM", what = "effect",
      main = "The Marginal Effects of Budget Increases\nOn Net Gross",
      xlab = "Budget (millions)",ylab = "Marginal effect of Additional Million to Budget")
```

# 2

# a) Linear Model for Movie Gross Regressed by Budget, Budget Squared, and Ratings

```{r}
mod3 <- lm(grossM ~ imdb_score + budgetM + I(budgetM^2) + 
             relevel(rating_simple,ref = "R"), data = movies_train)
summary(mod3)
```

# b)
When considering the coefficient for the G-rating on movies, it appears that G rated movies gross $33,250,000.00 more than R-rated movies.

# c) Predicted Values for Test and Training Sets
```{r}
trainingPredictions <- predict(mod3)
testPredictions <- predict(mod3,movies_test)
head(trainingPredictions)
head(testPredictions)
```

# d) The Residuals for Both the Test and Training Data are Shown Below
```{r}
trainingResids <- movies_train$grossM - trainingPredictions
testResids <- movies_test$grossM - testPredictions
head(trainingResids)
head(testResids)
```

# e)
```{r}
dummySet <- data.frame(trainingResids = trainingResids,
                       trainingPredictions = trainingPredictions,
                       movies_train)
ggplot(dummySet,aes(x = trainingPredictions,y = trainingResids)) + geom_point()+
   labs(title = "Residuals Against Predicted Values\nFor Train Data",
        y = "Training Resdiduals",x = "Training Predictions")
dummySet2 <- data.frame(testingResids = testResids,
                        testingPredictions = testPredictions,
                        movies_test)
ggplot(dummySet2,aes(x = testingPredictions,y = testingResids)) + geom_point()+
   labs(title = "Residuals Against Predicted Values\nFor Test Data",
        y = "Testing Resdiduals",x = "Testing Predictions")
```
From the above plots, it becomes clear that both sets of residuals and predicted values are heteroskedastic as their residuals vary widely as the predicted values change.  Plus the residuals do not appear to be equally distributed above and below zero, further indicative of heteroskedasticity.

# f)
```{r}
ggplot(dummySet,aes(x = grossM,y = trainingPredictions)) + geom_point()+
   labs(title = "Training Predictions Against True Values\nFor Train Data",
        y = "Training Predictions",x = "Training True Values")
ggplot(dummySet2,aes(x = grossM,y = testingPredictions)) + geom_point()+
   labs(title = "Testing Predictions Against True Values\nFor Test Data",
        y = "Testing Predictions",x = "Testing True Values")
```

# g) Examining RMSE of both Test and Train Sets

```{r}
RMSE <- function(t, p) {
   sqrt(sum(((t - p)^2)) * (1/length(t)))
}
rmse.train <-RMSE(movies_train$grossM,trainingPredictions)
rmse.test <-RMSE(movies_test$grossM,testPredictions)
accuracy(trainingPredictions,movies_train$grossM)
accuracy(testPredictions,movies_test$grossM)
print(rmse.train)
print(rmse.test)
```
Based on the root mean standard error caclulated for both the training and testing data, it becomes apparent that the model is not overfit.  This is due to the fact that the root mean squared error for both sets are similar, indicative of similar performance for both datasets. In the event that the test data had much larger root mean squared error than the training data, it would have been safe to say that the model was overfit to the training data. In this instance, however, this is not the case.

